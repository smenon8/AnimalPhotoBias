<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">

    <title>AWESOME Home</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1><u>A</u>nimal <u>W</u>ildlife <u>ES</u>timator using <u>SO</u>cial <u>ME</u>dia
        (A. W. E. S. O. M. E)</h1>
        <h2>AWESOME is a research project initiative to build a population estimator using pictures from social media. Tracking of wildlife population using conventional methods incurs a financial as well as an operational burden. AWESOME tries to solve this problem by turning to a promising and opportunistic form of citizen science. We are trying to build a population estimator by mining images of animals from social media. Estimating population from social media images is a non-trivial problem due to the inherent complexities introduced by biases in social media data. We attempt to quantify and understand the biases that influence the sharing behavior of human with respect to wildlife images. The first step towards building such an estimator that accounts from such self-reporting bias is to build a classifier that can learn whether or not a picture of a certain wildlife species will be shared or not.</h2>
        <h4>
        <a id="author-sreejith-menon" class="anchor" href="#author-sreejith-menon" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><b>Author:</b> Sreejith Menon
        <br> <b>Email:</b> smenon8@uic.edu
        <br>
        <a id="project-home-page-httpcompbiocsuicedusreejith" class="anchor" href="#project-home-page-httpcompbiocsuicedusreejith" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a> <b>Home-page: </b><a href="http://compbio.cs.uic.edu/%7Esreejith/">http://compbio.cs.uic.edu/~sreejith/</a>
        </h4>

        <section id="downloads" align="center">
          <a href="https://github.com/smenon8/AnimalWildlifeEstimator/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/smenon8/AnimalWildlifeEstimator/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/smenon8/AnimalWildlifeEstimator" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
          <a href="https://github.com/smenon8/AnimalWildlifeEstimator/wiki" class="btn btn-github"><span class="icon"></span>View GitHub Wiki</a>
        </section>
      </div>

      <div class="container" align="center">
          <section id="site-map">
          <a href="#tech-used" class="btn btn-primary">View Technology Stack</a>
          <a href="#project-overview" class="btn">View Project Progress</a>
          <a href="http://compbio.cs.uic.edu/~sreejith/ResultsDashboard.html" class="btn">View Results Dashboard</a>
          <a href="#script-index" class="btn btn-info">View Index</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">

      <h3>
      <a id="tech-used" class="anchor" href="#tech-used" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>Technology Stack</a></h3>
      <ul>
      <li>Python-3</li>
      <li>Jupyter-Notebook</li>
      <li>pandas</li>
      <li>matplotlib</li>
      <li>Plot.ly</li>
      <li>Folium</li>
      <li>sklearn</li>
      <li>sklearn-metrics</li>
      <li>Amazon Mechanical Turk</li>
      <li>Bash</li>
      <li>Windows Batch</li>

      </ul>

      <h3>
      <a id="project-overview" class="anchor" href="#project-overview" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>Project Progress</a></h3>

      <ul>
      <li>API available for extracting features of images and annotations from IBEIS.</li>
      <li>Completely automated the process for selection of images and creation of Amazon Mechanical Turk jobs. </li>
      <li>Completely automated deployment, approval and download for all the mechanical turk jobs.</li>
      <li>Completely automated parsing of .results file from the mechanical turk engine and return a python object/csv/json ready for processing.</li>
      <li>API available for both single as well multiple feature extraction for an images or a list of images (can be specified as a csv).</li>
      <li>API available to join features with the results and return python data-frames/csv/json for statistical calculation.</li>
      <li>API available for generating rank list of most shared pictures.</li>
      <li>API available for generating rank list by share proportion based on ecological features like species, sex, age, view_point of the animal.</li>
      <li>API available for generating rank lists for a specific feature across all albums or individual albums (number of shares for zebra in a particular album versus number of shares for giraffes etc.)</li>
      <li>API available to append the results from Amazon Mechanical Turk API with tags from Microsoft Image Tagging API and generate a rank list of most shared tags.</li>
      <li>Added functionality to generate reports of all statistics in HTML format with bar charts wherever necessary.</li>
      <li>API available for data prepartion for applying classifiers using the Bag-of-words methodology. </li>
      <li>API available for performing feature selection by calculating information gain of attributes with resepct to the target variable</li>
      <li>API available for building learning models like Logistic Regression, Support Vector Machines, Decision Trees and Random Forests and returning the predictions as well as performance metrics for the classifier. </li>
      <li>API available for visualizing the shared/not shared pictures on map and create clusters of share-no share homogenous region.</li>
      <li>API available for generating heat maps of the region of shared photos and not shared photos</li>
      <li>API available for applying mark-recapture and calculate the Petersen-Lincoln Index on the GZC data-set.</li>
      <li>API available for applying mark-recapture and calculate the Petersen-Lincoln Index on the shared GZC data-set obtained from the Mechanical Turk experiments.</li>
      <li>API available for extracting images from Flickr when the tags and text are specified.</li> 
      <li>API available for parallel download of images from Flickr and concurrent execution of image detection tasks on IBEIS. </li>
      </ul>
      
      <h3>
      <a id="script-index" class="anchor" href="#script-index" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>Available Scripts/Notebooks Index</a></h3>
      <div id="indexList">
      <ol>
      <li><p><a href="#GetPropertiesAPI"> GetPropertiesAPI.py </a></p>
        <ul>
          <li><a href="#getAnnotID">getAnnotID(gid)</a></li>
          <li><a href="#getImageFeature">getImageFeature(aid,feature)</a></li>
          <li><a href="#getExifData">getExifData(gidList,exifFtr)</a></li>
          <li><a href="#getContributorGID">getContributorGID(cid)</a></li>
          <li><a href="#getAgeFeatureReadableFmt">getAgeFeatureReadableFmt(ageList)</a></li>
          <li><a href="#getUnixTimeReadableFmt">getUnixTimeReadableFmt(unixtm)</a></li>
        </ul>
      </li>
      
      <li><p><a id="generate-mturk-file-api" href="#generate-mturk-file-api"> GenerateMTurkFileAPI.py </a></p>
        <ul>
        <li><a href="#genRandomImg">genRandomImg(begin,end,oldList)</a></li>
        <li><a href="#genImageList">genImageList(begin,stop,maxImgs)</a></li>
        <li><a href="#generateMTurkFile">generateMTurkFile(startGID,endGID,outFile,maxImgs,prodFileWrite)</a></li>
        </ul>
      </li>
      
      <li><p><a href="#CreateTurkFilesBulk"> CreateTurkFilesBulk.py </a></p>
        <ul>
          <li><a href="#createTurkFilesBulk">createTurkFilesBulk(flNm,jobMapName,noOfJobs,noOfImgsPerJob)</a></li> 
        </ul>
      </li>
      
      <li><p><a href="#BuildConsolidatedFeaturesFile.py"> BuildConsolidatedFeaturesFile.py </a></p>
      <ul> 
        <li><a href="#printCompltnPercent">printCompltnPercent(percentComplete)</a></li>
        <li><a href="#writeCsvFromDict">writeCsvFromDict(header,inDict,outFL)</a></li>
        <li><a href="#genJsonFromMSAIData">genJsonFromMSAIData(flName,outFlNm)</a></li>
        <li><a href="#buildFeatureFl">buildFeatureFl(inp,outFL,isInpFl)</a></li>
        <li><a href="#buildExifFeatureFl">buildExifFeatureFl(inp,outFL,isInpFl)</a></li>
      </ul>
      </li>

      <li><p><a href="#JobsMapResultsFilesToContainerObjs"> JobsMapResultsFilesToContainerObjs.py </a></p>
      <ul>
        <li><a href="#genUniqueImageListFromMap">genUniqueImageListFromMap(mapFlName)</a></li>
        <li><a href="#genAlbumGIDDictFromMap">genAlbumGIDDictFromMap(mapFlName)</a></li>
        <li><a href="#genImgAlbumDictFromMap">genImgAlbumDictFromMap(mapFLName)</a></li>
        <li><a href="#getImageFreqFromMap">getImageFreqFromMap(inFL)</a></li>
        <li><a href="#genAidGidDictFromMap">genAidGidDictFromMap(mapFL)</a></li>
        <li><a href="#genGidAidDictFromMap">genGidAidDictFromMap(mapFL)</a></li>
        <li><a href="#genAidGidTupListFromMap">genAidGidTupListFromMap(mapFL)</a></li>
        <li><a href="#genAidFeatureDictList">genAidFeatureDictList(mapFL)</a></li>
        <li><a href="#genAidFeatureDictDict">genAidFeatureDictDict(mapFL)</a></li>
        <li><a href="#extractImageFeaturesFromMap">extractImageFeaturesFromMap(gidAidMapFl,aidFtrMapFl,feature)</a></li>
        <li><a href="#createResultDict">createResultDict(jobRangeStart,jobRangeEnd,workerData)</a></li>
        <li><a href="#imgShareCountsPerAlbum">imgShareCountsPerAlbum(imgAlbumDict,results)</a></li>
        <li><a href="#genMSAIDataHighConfidenceTags">genMSAIDataHighConfidenceTags(tagInpDataFl,threshold)</a></li>
        <li><a href="#auditResMap">auditResMap(imgAlbumDict,resultList)</a></li>
      </ul>
      </li>

      <li><p><a href="#DeriveFinalResultSet"> DeriveFinalResultSet.py </a></p>
      <ul>
        <li><a href="#getPosShrProptn">getPosShrProptn(imgJobMap,resStart,resEnd)</a></li>
        <li><a href="#genTotCnts">genTotCnts(ovrCnts)</a></li>
        <li><a href="#getShrProp">getShrProp(ovrAggCnts)</a></li>
        <li><a href="#getCountingLogic">getCountingLogic(gidAidMapFl,aidFeatureMapFl,feature,withNumInds)</a></li>
        <li><a href="#genAlbmFtrs">genAlbmFtrs(gidAidMapFl,aidFeatureMapFl,imgJobMap,reqdFtrList)</a></li>
        <li><a href="#getShrPropImgsAcrossAlbms">getShrPropImgsAcrossAlbms(imgJobMap,resSetStrt,resSetEnd,flNm)</a></li>
        <li><a href="#getFltrCondn">getFltrCondn(ftr)</a></li>
        <li><a href="#genObjsForConsistency">genObjsForConsistency(gidAidMapFl,aidFeatureMapFl,ftr,imgJobMap,resSetStrt,resSetEnd)</a></li>
        <li><a href="#getConsistencyDict">getConsistencyDict(filteredKeyArr,ftrAlbmDict,ftrAlbmShrPropDict,flNm)</a></li>
        <li><a href="#genVarStddevShrPropAcrsAlbms">genVarStddevShrPropAcrsAlbms(consistency)</a></li>
        <li><a href="#ovrallShrCntsByFtr">ovrallShrCntsByFtr(gidAidMapFl,aidFeatureMapFl,feature,imgJobMap,resSetStrt,resSetEnd)</a></li>
        <li><a href="#shrCntsByFtrPrAlbm">shrCntsByFtrPrAlbm(gidAidMapFl,aidFeatureMapFl,feature,imgJobMap,resSetStrt,resSetEnd)</a></li>
        <li><a href="#ovrallShrCntsByTwoFtrs">ovrallShrCntsByTwoFtrs(gidAidMapFl,aidFeatureMapFl,ftr1,ftr2,imgJobMap,resSetStrt,resSetEnd)</a></li>
        <li><a href="#genNumIndsRankList">genNumIndsRankList()</a></li> 
      </ul>
      </li>
	
	  <li><p><a href="#BaseCapsuleClass"> BaseCapsuleClass.py</a></p>
      <ul>
        <li><a href="#CapsuleClassAttribs">Object Attributes</a></li>
        <li><a href="#runClf">runClf()</a></li>
        <li><a href="#setTestAttrib">setTestAttrib(clsAttribStr,value):</a></li>
      </ul>
      </li>
	  
	  <li><p><a href="#RegressionCapsuleClass"> RegressionCapsuleClass.py</a></p>
      <ul>
        <li><a href="#CapsuleClassAttribs">Object Attributes</a></li>
        <li><a href="#runClf">runClf()</a></li>
        <li><a href="#evalClassifierPerf">evalClassifierPerf()</a></li>
		<li><a href="#removeOutliers">removeOutliers()</a></li>
      </ul>
      </li>
	  
      <li><p><a href="#ClassifierCapsuleClass"> ClassifierCapsuleClass.py</a></p>
      <ul>
        <li><a href="#CapsuleClassAttribs">Object Attributes</a></li>
        <li><a href="#runClf">runClf()</a></li>
        <li><a href="#evalClassifierPerf">evalClassifierPerf()</a></li>
      </ul>
      </li>

      <li><p><a href="#ClassifierHelperAPI"> ClassifierHelperAPI.py </a></p>
      <ul>
        <li><a href="#genHead">genHead(dataDict,ftr)</a></li>
        <li><a href="#getMasterData">getMasterData(flNm)</a></li>
        <li><a href="#genAttribsHead">genAttribsHead(data,ftrList)</a></li>
        <li><a href="#createDataFlDict">createDataFlDict(data,allAttribs,threshold,dataMode,writeTempFiles)</a></li>
        <li><a href="#getLearningAlgo">getLearningAlgo(methodName,kwargs)</a></li>
        <li><a href="#trainTestSplitter">trainTestSplitter(gidAttribDict,allAttribs,trainTestSplit)</a></li>
        <li><a href="#buildBinClassifier">buildBinClassifier(data,allAttribs,trainTestSplit,threshold,methodName,extremeClf)</a></li>
        <li><a href="#genAllAttribs">genAllAttribs(masterDataFl,constraint,infoGainFlNm</a></li>
		    <li><a href="#buildRegrMod">buildRegrMod(train_data_fl,allAttribs,trainTestSplit,methodName,kwargs)</li></a>
        
      </ul>
      </li>

      <li><p><a href="#FeatureSelectionAPI"> FeatureSelectionAPI.py</a></p>
      <ul>
        <li><a href="#dataEntropy">dataEntropy(attribute)</a></li>
        <li><a href="#getNextEle">getNextEle(attribList)</a></li>
        <li><a href="#infoGain">infoGain(attribute,targetAttribute)</a></li>
      </ul>
      </li>

      <li><p><a href="#MarkRecapHelper"> MarkRecapHelper.py</a></p>
      <ul>
        <li><a href="#createFlickrObj">createFlickrObj(flickrKeyFl)</a></li>
        <li><a href="#applyMarkRecap">applyMarkRecap(nidMarkRecapSet)</a></li>
        <li><a href="#genSharedGids">genSharedGids(gidList,gidPropMapFl)</a></li>
      </ul>
      </li>
	  
	  <li><p><a href="#PopulationEstimatorFromClf"> PopulationEstimatorFromClf.py</a></p>
      <ul>
        <li><a href="#trainTestClf">trainTestClf(train_data_fl,test_data_fl,clf,attribType,infoGainFl,clfArgs)</a></li>
        <li><a href="#estimatePopulation">estimatePopulation(prediction_results,inExifFl,inGidAidMapFl,inAidFtrFl)</a></li>
        <li><a href="#biasedCoinFlipper">biasedCoinFlipper(p)</a></li>
        <li><a href="#trainTestRgrs">trainTestRgrs(train_data_fl,test_data_fl,methodName,attribType,infoGainFl,methArgs)</a></li>
        <li><a href="#kSharesPerContributor">kSharesPerContributor(prediction_probabs,inExifFl,inGidAidMapFl,inAidFtrFl,genk)</a></li>
        <li><a href="#kSharesPerContribAfterCoinFlip">kSharesPerContribAfterCoinFlip(prediction_results,inExifFl,inGidAidMapFl,inAidFtrFl,genk)</a></li>
		    <li><a href="#runSyntheticExpts">runSyntheticExpts(inExifFl,inGidAidMapFl,inAidFtrFl,krange)</a></li>
        <li><a href="#runSyntheticExptsRgr">runSyntheticExptsRgr(inExifFl,inGidAidMapFl,inAidFtrFl,krange)</a></li>
        <li><a href="#runSyntheticExptsClf">runSyntheticExptsClf(inExifFl,inGidAidMapFl,inAidFtrFl,krange)</a></li>
      </ul>
      </li>
	  

      <li><p><a href="#SocialMediaImageExtracts"> SocialMediaImageExtracts.py</a></p>
      <ul>
        <li><a href="#createFlickrObj">createFlickrObj(flickrKeyFl)</a></li>
        <li><a href="#searchInFlickr">searchInFlickr(flickrObj,tags,text)</a></li>
      </ul>
      </li>

      <li><p><a href="#AppendMicrosoftAIData"> AppendMicrosoftAIData.ipynb </a></p> </li>
      <li><p><a href="#VisualizeResults"> VisualizeResults.ipynb </a></p> </li>
      <li><p><a href="#ImageShareabilityClassifiers"> ImageShareabilityClassifiers.ipynb </a></p> </li>
      <li><p><a href="#InterAnnotatorAgreement"> InterAnnotatorAgreement.ipynb </a></p> </li>
      <li><p><a href="#LocationBiasCheck"> LocationBiasCheck.ipynb </a></p> </li>




      </ol>
      </div>
    <br>

      <h3>
      <a id="GetPropertiesAPI" class="anchor" href="#GetPropertiesAPI" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>GetPropertiesAPI.py</a></h3>
      <div id="descContent"><p>
      Description: Contains methods to extract specific information from IBEIS database through REST-ful API calls.</p></div>
      <div id="codeContent">
      <ul>
      <li><a id="getAnnotID" href="#getAnnotID">getAnnotID(gid) </a></li>
      <p>
              a.  Argument: GID of a single image. <br>
              b.  Argument data-type: int/str <br>
              c.  PRE-condition: <br>
              
              &nbsp &nbsp i.  gid should be a valid image ID <br> 
              d.  Returns: Corresponding Annotation IDs in the image. <br>
              e.  Return data-type: Python list object <br>
              f.  Comments: Used to extract annotation IDs for a particular image GID <br>  
      </p>

      <li><a id="getImageFeature" href="#getImageFeature">getImageFeature(aidList,feature)</a></li>
      <p>
              a.  Arguments: List of Annotation IDs, Required Feature <br>
              b.  Argument data-type: Python list, str <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  aid should be a valid annotation ID <br>
              &nbsp &nbsp  ii. feature should be from the set: {"age/months", "yaw/text", "exemplar", "quality/text", "sex/text", "species/text", "name/rowid", "name/text", "image_contributor_tag"} <br>
              d.  Returns: Corresponding feature of the specified annotation ID <br>
              e.  Return data-type: Python list object <br>
              f.  Comments: Used to extract features for a given list of annotation IDs. <br>
      </p>
      
      <li><a id="getExifData" href="#getExifData">getExifData(gidList,exifFtr)</a></li>
      <p>
              a.  Arguments: List of GIDs, Required EXIF Feature <br>
              b.  Argument data-type: Python list, str <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  GID should be a valid image in IBEIS database <br>
              &nbsp &nbsp  ii. feature should be from the set: {unixtime, lat, long} <br>
              d.  Returns: Corresponding EXIF feature for the specified image <br>
              e.  Return data-type: Python list object <br>
              f.  Comments: Used to extract EXIF features for a given list of image GIDs. <br>
      </p>

      <li><a id="getContributorGID" href="#getContributorGID">getContributorGID(cid)</a></li>
      <p>
              a.  Arguments: Contributor ID <br>
              b.  Argument data-type: int/str <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  cid should be a valid contributor ID <br>
              d.  Returns: List of images clicked by the contributor <br>
              e.  Return data-type: Python list object <br>
              f.  Comments: Used to extract all images clicked by a particular photographer. <br>
      </p>

      <li><a id="getAgeFeatureReadableFmt" href="#getAgeFeatureReadableFmt">getAgeFeatureReadableFmt(ageList)</a></li>
      <p>
              a.  Arguments: Age as extracted from IBEIS API call. <br>
              b.  Arguments data-type: Python list. <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Age should be in one of the following formats: [[-1,-1]] or [[None,2]] or [[3, 5]] or [[6, 11]] or [[12,23]] or [[24,35]] or [[36,None]] <br>
              d.  Returns: A human readable string of the age. <br>
              e.  Comments: Age in IBEIS is stored as a list (an estimated range in months). IBEIS identifies the age of the animal up to 3 years. The animals will be classified as Infants, a year-old juveniles, two-year-old juveniles or fully grown adults. <br>
      </p>
  
      <li><a id="getUnixTimeReadableFmt" href="#getUnixTimeReadableFmt">getUnixTimeReadableFmt(unixtm)</a></li>
      <p>
              a.  Arguments: Unixtime as extracted from IBEIS API call. <br>
              b.  Arguments data-type: int <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  The unix time provided in the input should be a valid unix time in integer form. <br>
              d.  Returns: A human readable string of the unixtime in YYYY-MM-DD HH:mm:ss. <br>
              e.  Comments: The time each picture is taken is stored in unix time format. This method is short-hand method to convert the unix time into a human readable date time. This method makes necessary adjustments to take into consideration UTC times or in other words adjusts for daylight saving changes.<br>
      </p>
      </ul>
      </div>
      <br>
      
      <h3>
      <a id="GenerateMTurkFileAPI" class="anchor" href="#GenerateMTurkFileAPI" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>GenerateMTurkFileAPI.py</a></h3>
      <div id="descContent"><p>
      Description: Contains methods to generate a single mechanical turk photo album. There are multiple methods in the API but the method generateMTurkFile() needs to be called to generate one image album job file.
      <br>
      <i>Hardcoded parameter: excepFL – points to the CSV file which is a enumeration of all identified human images. This is provided to avoid occurrences of human images in the mechanical turk photo album jobs.</i>  
      </p></div>    
      <div id="codeContent">
      <ul>
      <li><a id="genRandomImg" href="#genRandomImg">genRandomImg(begin,end,oldList)</a></li>
      <p>
              a.  Arguments: Start range, End Range and list in the same range <br>
              b.  Argument data-type: int, int, int <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  All elements in the oldList should be in the range [begin, end] <br>
              &nbsp &nbsp ii. begin, end should be valid image GIDs. <br>
              d.  Returns: A randomly selected image GID in the range [begin, end] and not in oldList. <br>
              e.  Return data-type: int <br>
              f.  Comments: This method is used when there arises a case when a particular image in the image album have to be replaced with another randomly selected image. <br>
      </p>

      <li><a id="genImageList" href="#genImageList">genImageList(begin,stop,maxImgs=20)</a></li>
      <p>
              a.  Arguments: Start range, end range and number of images in photo album <br>
              b.  Argument data-type: int, int, int <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  begin and stop should be both valid image GID’s. <br>
              &nbsp &nbsp ii. begin < stop <br>
              &nbsp &nbsp iii.  stop – begin > maxImgs <br>
              d.  Returns: A python list with randomly selected image GID’s that are in the range [begin, stop] and len(list) = maxImgs <br>
              e.  Comments: This method is used to generate a list of random images that will be further used as an input to the method that generates the photo album mechanical turk job. The list has no duplicates and has exactly maxImgs number of images. <br>
      </p>

      <li><a id="generateMTurkFile" href="#generateMTurkFile">generateMTurkFile(startGID,endGID,outFile,maxImgs=20,prodFileWrite=False)</a></li>
      <p>
              a.  Arguments: Start GID, end GID, name of output file, number of images in photo album, a boolean to generate a m-turk job for production environment. <br>
              b.  Argument data-type: int, int, str, int, boolean <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  startGID and endGID should be both valid image GID’s. <br>
              &nbsp &nbsp ii. startGID < endGID <br>
              &nbsp &nbsp iii.  endGID - startGID > maxImgs <br>
              d.  Returns: A python list with randomly selected image GID’s that are in the photo album. The GID’s are in the range [startGID, endGID] and len(list) = maxImgs <br>
              e.  Comments: Most important method of this script. This generates a .question file that is fed to createHIT command. If prodFileWrite parameter is set to True, then a job with the same image GID’s is generated with the word ‘prod’ appended to the outFile name. prodFileWrite is defaulted to False, so it will only generate a file for mechanical turk sandbox if this parameter is unspecified. <br>
      </p>
      </ul>
      </div>
      
      <h3>
      <a id="CreateTurkFilesBulk" class="anchor" href="#CreateTurkFilesBulk" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>CreateTurkFilesBulk.py</a></h3>
      <div id="descContent"><p>
      Description: Contains a single method that generates mechanical turk jobs for generating photo-albums in bulk. This script contains a __main__() method that accepts command line arguments and can be directly executed through terminal. <br><br>
      To run the script, provide 4 parameters in the order fileName, jobMapName, numberOfFiles, numberOfImgs. <br>
      python CreateTurkFilesBulk.py /tmp/sample /tmp/sample.CSV 2 10 <br>
      Successfully written : /tmp/sample1 <br>
      Successfully written : /tmp/sample2 <br></p></div>

      <div id="codeContent">
      <ul>
      <li><a id="createTurkFilesBulk" href="#createTurkFilesBulk">createTurkFilesBulk(flNm,jobMapName,noOfJobs,noOfImgsPerJob = 20)</a></li>
      <p>
              a.  Arguments: File Name prefix of the job files, File name of the map file of albums and the images in those albums, number of jobs needed, number of images needed per job. <br>
              b.  Argument data-type: str, str, int, int <br>
              c.  PRE-condition:  <br>
              &nbsp &nbsp i.  Entire path is provided for both flNm and jobMapName. <br>
              &nbsp &nbsp ii. Path exists in the host system. <br>
              d.  Returns: None <br>
              e.  Comments: Selects noOfJobs number of random contributors (there might be duplicates in the selected contributor list). There is hard-coded code for removing contributors who did not click any picture. For each job, noOfImgsPerJob number of images are selected from the range of images a particular contributor has clicked. This is done to ensure that given a particular album, all the images are clicked by the same contributor. The script assumes the value of prodFileWrite in line 63 as True. It generates 1 input, 1 question file per noOfJobs and 1 map file that contains a map between albums and the images in them. <br>
      </p>
      </ul>
      </div>

      <br>
      <h3>
      <a id="DeriveFinalResultSet" class="anchor" href="#DeriveFinalResultSet" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>DeriveFinalResultSet.py</a></h3>
      <div id="descContent"><p>
      Description: Contains multiple methods to calculate final result statistics. The methods in this script file highly utilizes objects created by JobsMapResultsFilesToContainerObjs.py. Three global variables are declared in the scope of this project, the currently point to CSV files that have information from second phase of the mechanical turk deployment. <br><br>
      gidAidMapFl, aidFeatureMapFl, imgJobMap <br>
      These parameters are used by multiple methods within this script. <br></p></div>
      <div id="codeContent">
      <ul>
      <li><a id="getPosShrProptn" href="#getPosShrProptn">getPosShrProptn(imgJobMap,resStart,resEnd)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format, start of the results file, end of the results files. <br>
              b.  Argument data-type: str, int, int <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              &nbsp &nbsp ii. All files starting from photo_album_<resStart>.results until photo_album_<resEnd>.results should exist under results folder.<br>
              b.  Returns: A Python dictionary object that has position of images in the album and number of shares, number of not_shares, the total and the proportion of share rate as a nested dictionary. <br>
              c.  Comments:  Number of shares/not shares for each and every position are enumerated inside a list. Use of OrderedDict() from the Python collections framework ensures that the records are picked in the exact same order they appear in the albums. This returned dictionary can then be embedded inside a data-frame and can be visualized. <br>
      </p>

      <li><a id="genTotCnts" href="#genTotCnts">genTotCnts(ovrCnts)</a></li>
      <p>
              a.  Arguments: Overall counts dictionary, an enumeration of share/no share data per image. <br>
              b.  Arguments data-type: Python dictionary object. <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  The values in the argument dictionary should be a Python list object. <br>
              &nbsp &nbsp ii. All the values in the list are integers. <br>
              d.  Returns: A python dictionary which has the same keys as the argument data-type, but the values are simply the sum total of all values in the list corresponding to the argument dictionary key. <br>
              e.  Comments: This method is a simplification of adding up the share/no share counts of a particular image. For example, for a particular image which appeared in 5 different albums, the share rates were 9,5,9,10,10. This method will return gid:sum([9,5,9,10,10)]. <br>
      </p>

      <li><a id="getShrProp" href="#getShrProp">getShrProp(ovrAggCnts)</a></li>
      <p>
              a.  Arguments: Overall Aggregate counts, typically outputted by genTotCnts method. A python dictionary with key and sum total of shares, no_shares and totals. <br>
              b.  Arguments data-type: Python dictionary object.<br>
              c.  PRE-condition:<br>
              &nbsp &nbsp i.  The value in the argument dictionary should a single valued integer. <br>
              &nbsp &nbsp ii. The key should be a iterable, most preferably a Python tuple object.  <br>
              &nbsp &nbsp iii.  Keys should contain the strings: ‘share’, ‘total’ or ‘not_share’<br>
              d.  Returns: A python dictionary which is simply the share proportion of that particular key. <br>
              e.  Comments: This method will be used to calculate the share proportion of a particular feature or an image. This dictionary answers the question, what percentage of this feature/image were shared. The share proportion is calculated as total_shares/(total_shares+total_not_shares). <br>
      </p>
 
      <li><a id="getCountingLogic" href="#getCountingLogic">getCountingLogic(gidAidMapFl,aidFeatureMapFl,feature,withNumInds=True)</a></li>
      <p>
              a.  Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), feature, number of individuals in the output required (defaulted to True) <br>
              b.  Arguments data-type: str, str, str, boolean <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for gidAidMapFl and aidFeatureMapFl and the file should exist in JSON file format. <br>
              &nbsp &nbsp ii. Should be from an acceptable set of feature strings. <br>
              d.  Returns: A Python dictionary object. <br>
              e.  Comments: This method defines the counting logic for a particular image for a given feature. The counting logic will return an optional number of individuals in the result dictionary if the aparamerter withNumInds is set to True. For instance, for the feature ‘SPECIES’, there might be images that contains both a zebra and a giraffe. In that case, the share counts have to be added to both zebra and giraffe. <br>
      </p>

      <li><a id="genAlbmFtrs" href="#genAlbmFtrs">genAlbmFtrs(gidAidMapFl,aidFeatureMapFl,imgJobMap,reqdFtrList)</a></li>
      <p>
              a.  Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), Image GID-Album map file(CSV), required features list – a list of features for which the properties needs to be determined. <br>
              b.  Arguments data-type: str, str, str, Python List <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for gidAidMapFl and aidFeatureMapFl and the file should exist in JSON file format. <br>
              &nbsp &nbsp ii. Entire path is provided for imgJobMap and the file should exist in CSV format. <br>
              &nbsp &nbsp iii.  The feature list should contain elements from the acceptable set of features. <br>
              d.  Returns: A Python dictionary object. <br>
              e.  Comments: This method is used to generate the number of shares and not_shares per feature in a particular album. For instance, if the required features list contains ‘SPECIES’, then it tells the share and not_share count per album for each available/identifiable species. <br>
      </p>

      <li><a id="getShrPropImgsAcrossAlbms" href="#getShrPropImgsAcrossAlbms">getShrPropImgsAcrossAlbms(imgJobMap,resSetStrt,resSetEnd,flNm)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format, start of the results file, end of the results files, output file name in json format. <br>
              b.  Arguments data-type: str, int, int, str <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist. <br>
              &nbsp &nbsp ii. All files starting from photo_album_&ltresStart&gt.results until photo_album_&ltresEnd&gt.results should exist under results folder. <br>
              d.  Returns: Two Python Dictionary objects. <br>
              e.  Comments: This method derives the share proportions of images across different albums as opposed to generating an overall proportion of images. For example, the output of this method will contain how many times a particular image was shared in a particular album. This is particularly insightful for images that appear across multiple albums. It could essentially tell if a certain image was shared in the same way or differently and if the share rate of an image is orthogonal to the context of album. <br>
      </p>

      <li><a id="getFltrCondn" href="#getFltrCondn">getFltrCondn(ftr)</a></li>
      <p>
       		  a. Arguments: Feature name <br>
       		  b. Arguments data-type: str <br>
       		  c. PRE-condition: <br>
       		  &nbsp &nbsp i. Provided argument should be a valid feature. <br>
       		  d. Returns: A lambda function  <br>
       		  e. Comments: This method returns a lambda function or a logic in filtering all valid rows without the UNIDENTIFIED. A slight adjustment is needed depending on what feature is being filtered. <br>
      </p>

     <li><a id="genObjsForConsistency" href="#genObjsForConsistency">genObjsForConsistency(gidAidMapFl,aidFeatureMapFl,ftr,imgJobMap,resSetStrt,resSetEnd)</a></li>
     <p>
      		  a. Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), Feature name, Image GID-Album map file(CSV), start of the results file, end of the results files.<br>
       		  b. Arguments data-type: str, str, str, str, int, int <br>
       		  c. PRE-condition: <br>
       		   &nbsp &nbsp i.  Entire path is provided for gidAidMapFl and aidFeatureMapFl and the file should exist in JSON file format. <br>
              &nbsp &nbsp ii. Entire path is provided for imgJobMap and the file should exist in CSV format. <br>
              &nbsp &nbsp iii.  The feature list should contain elements from the acceptable set of features. <br>
       		  d. Returns: Python List Object, Two Python Dictionary objects  <br>
       		  e. Comments: This is a helper method for <a href="#getConsistencyDict">getConsistencyDict()</a>. It returns three objects. <br>
            &nbsp &nbsp i. A list with only valid features i.e. without the UNIDENTIFIED entries. <br>
            &nbsp &nbsp ii. A dictionary object that contains the albums in which a particular feature is seen. Ex. GIRAFFE is seen in albums 1, 3,4,5 etc. <br>
            &nbsp &nbsp iii. A dictionary object that contains the share proportion of feature per album. Ex. giraffes in album 1 were shared 70% of times etc. Format of the key: (feature, album)<br>
      </p>

      <li><a id="getConsistencyDict" href="#getConsistencyDict">getConsistencyDict(filteredKeyArr,ftrAlbmDict,ftrAlbmShrPropDict,flNm)</a></li>
      <p>
            a. Arguments: The filtered key array, Feature Album dictionary and feature album share proportion dictionary are direct outputs of <a href="#genObjsForConsistency">genObjsForConsistency()</a> <br>
            b. Arguments data-type: Python List Object, Python Dictionary Object, Python Dictionary object, str <br>
            c. PRE-condition: Same conditions as <a href="#genObjsForConsistency">genObjsForConsistency()</a> <br>
            d. Returns: A Python Dictionary object. <br>
            e. Comments: This method should be thought as the main counting logic while calculating the share rate related statistic for any feature that is extracted from IBEIS. The output dictionary is all the valid features and thier share-rates across different albums. The output dictionary is a key - dictionary pair. Ex. {giraffe : {album_1 : 70, album_2 : 89}, ...}

      </p>

      <li><a id="genVarStddevShrPropAcrsAlbms" href="#genVarStddevShrPropAcrsAlbms">genVarStddevShrPropAcrsAlbms(consistency)</a></li>
      <p>
            a. Arguments: Consistency dictionary is the direct ouput of <a href="#getConsistencyDict">getConsistencyDict()</a> <br>
            b. Arguments data-type: Python Dictionary object <br>
            c. PRE-condition: Same conditions as <a href="#genObjsForConsistency">genObjsForConsistency()</a> <br>
            d. Returns: A Python Dictionary object. <br>
            e. Comments: As the method name suggests, this method generates the mean, variance and standard deviation for a particular feature element for across different albums. <br>
      </p>

      <li><a id="ovrallShrCntsByFtr" href="#ovrallShrCntsByFtr">ovrallShrCntsByFtr(gidAidMapFl,aidFeatureMapFl,feature,imgJobMap,resSetStrt,resSetEnd)</a></li>
      <p>
            a. Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), Feature name, Image GID-Album map file(CSV), start of the results file, end of the results files.<br>
            b. Arguments data-type: str, str, str, str, int, int <br>
            c. PRE-condition: <br>
             &nbsp &nbsp i.  Entire path is provided for gidAidMapFl and aidFeatureMapFl and the file should exist in JSON file format. <br>
              &nbsp &nbsp ii. Entire path is provided for imgJobMap and the file should exist in CSV format. <br>
              &nbsp &nbsp iii.  The feature list should contain elements from the acceptable set of features. <br>
            d. Returns: A Python Dictionary object. <br>
            e. Comments: This method generates the overall share statistic for every element of a particular feature. The logic involves simple counting for each element of the feature based on the counting logic (refer <a href="#getCountingLogic">getCountingLogic()</a>). This explicitly handles the images where there are multiple features and the counts are made in each of the feature. This method is ideal for getting share rate of a particular feature across the entire experiment, not limited by album. In other words, the result dict has share proportions calculated across albums. <br>
      </p>

      <li><a id="shrCntsByFtrPrAlbm" href="#shrCntsByFtrPrAlbm">shrCntsByFtrPrAlbm(gidAidMapFl,aidFeatureMapFl,feature,imgJobMap,resSetStrt,resSetEnd)</a></li>
      <p>
            a. Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), Feature name, Image GID-Album map file(CSV), start of the results file, end of the results files.<br>
            b. Arguments data-type: str, str, str, str, int, int <br>
            c. PRE-condition: <br>
             &nbsp &nbsp i.  Entire path is provided for gidAidMapFl and aidFeatureMapFl and the file should exist in JSON file format. <br>
              &nbsp &nbsp ii. Entire path is provided for imgJobMap and the file should exist in CSV format. <br>
              &nbsp &nbsp iii.  The feature list should contain elements from the acceptable set of features. <br>
            d. Returns: A Python Dictionary object. <br>
            e. Comments: This method generates the share statistic for every element of a particular feature for each album in which there are some instances with the said feature. The logic involves simple counting for each element of the feature based on the counting logic (refer <a href="#getCountingLogic">getCountingLogic()</a>). This explicitly handles the images where there are multiple features and the counts are made in each of the feature. This method is ideal for getting share rate of a particular feature across the entire experiment by album. In other words, this should used to calculate and compare the share rates of a particular feature and how it changes across different albums. As a sidenote, if the same feature is being shared differently across albums, then it means there is some contextual information from the album that is dominating this effect.<br>
      </p>

      <li><a id="ovrallShrCntsByTwoFtrs" href="#ovrallShrCntsByTwoFtrs">ovrallShrCntsByTwoFtrs(gidAidMapFl,aidFeatureMapFl,ftr1,ftr2,imgJobMap,resSetStrt,resSetEnd)</a></li>
      <p>
            a. Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), Feature name 1, Feature name 2, Image GID-Album map file(CSV), start of the results file, end of the results files.<br>
            b. Arguments data-type: str, str, str, str, int, int <br>
            c. PRE-condition: <br>
             &nbsp &nbsp i.  Entire path is provided for gidAidMapFl and aidFeatureMapFl and the file should exist in JSON file format. <br>
              &nbsp &nbsp ii. Entire path is provided for imgJobMap and the file should exist in CSV format. <br>
              &nbsp &nbsp iii.  The feature list should contain elements from the acceptable set of features. <br>
            d. Returns: A Python Dictionary object. <br>
            e. Comments: This method is used to generate cross statistic for two features. For example, this question typically answers questions like <i>How many <b>giraffes</b> that were looking <b>left</b> were shared? Or How many <b>infants</b> that were <b>males</b> were shared?</i><br>
            The logic involves simple counting for each element of the feature based on the counting logic (refer <a href="#getCountingLogic">getCountingLogic()</a>). Since there are two features to be dealt here, the instances are divided into even and uneven features. Even features are defined as when the number of instances of feature 1 and feature 2 are identical. Uneven features on the other hand are when the number of instances of feature 1 and feature 2 are not identical. Uneven features are handled differently for 1-many, many-1 and many-many.<br>
      </p>

      <li><a id="genNumIndsRankList" href="#genNumIndsRankList">genNumIndsRankList()</a></li>
      <p>
          a. Arguments: <br>
          b. Arguments data-type: <br>
          c. PRE-condition: <br>
          d. Returns: A Python Dictionary object. <br>
          e. Comments: As the method name suggests, this method generates the rank list of number of individuals in an image by share proportion. There is an active issue being tracked to parametrize this method for future use at  <a href="https://github.com/smenon8/AnimalPhotoBias/issues"> GitHub  Issues</a><br>
      </p>
      </ul>
      </div>

    <br>
      <h3>
      <a id="JobsMapResultsFilesToContainerObjs" class="anchor" href="#JobsMapResultsFilesToContainerObjs" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>JobsMapResultsFilesToContainerObjs.py</a></h3>
      <div id="descContent"><p>
      Description: Contains methods that generates a Python Object from different map files. This method gives an interface for building required data structures to compute various stastistics. There are multiple methods that output CSV or JSON or both. Use methods in this script to generate easy-to-use Python objects. There are methods that parse the .results file that is extracted from Amazon Mechanical Turk jobs.<br>
      <i>Note that the method names are very similar and take same argument in most cases.</i></p></div>
      <div id="codeContent">
      <ul>
      <li><a id="genUniqueImageListFromMap" href="#genUniqueImageListFromMap">genUniqueImageListFromMap(mapFlName)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python List Object <br>
              e.  Comments: This method is used to generate a list of all images that are used in the current experiment as specified by the map file.<br>
      </p>

      <li><a id="genAlbumGIDDictFromMap" href="#genAlbumGIDDictFromMap">genAlbumGIDDictFromMap(mapFlName)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python Dictionary Object <br>
              e.  Comments: This method is used to generate a dictionary in the form { Album : [GIDS] }. This object will give us the capability to query which images exist in a particular album.<br>
      </p>

      <li><a id="genImgAlbumDictFromMap" href="#genImgAlbumDictFromMap">genImgAlbumDictFromMap(mapFlName)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python Dictionary Object <br>
              e.  Comments: This method is used to generate a dictionary in the form { GID: [Albums] }. This object will give us the capability to query which album contain a particular GID.<br>
      </p>

      <li><a id="getImageFreqFromMap" href="#getImageFreqFromMap">getImageFreqFromMap(inFL)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python Dictionary Object <br>
              e.  Comments: This method is used to generate a dictionary in the form { GID : No. of albums it appears }. <br>
      </p>

      <li><a id="genAidGidDictFromMap" href="#genAidGidDictFromMap">genAidGidDictFromMap(mapFL)</a></li>
      <p>
              a.  Arguments: GID-AID map file(JSON) <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python Dictionary Object <br>
              e.  Comments: This method is used to generate a dictionary in the form { AID : GID }. <br>
      </p>

      <li><a id="genGidAidDictFromMap" href="#genGidAidDictFromMap">genGidAidDictFromMap(mapFL)</a></li>
      <p>
              a.  Arguments: GID-AID map file(JSON) <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python Dictionary Object <br>
              e.  Comments: This method is used to generate a dictionary in the form { GID : List of AIDs in that image }. <br>
      </p>

      <li><a id="genAidGidTupListFromMap" href="#genAidGidTupListFromMap">genAidGidTupListFromMap(mapFL)</a></li>
      <p>
              a.  Arguments: GID-AID map file(JSON) <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python List Object (A list of tuples)<br>
              e.  Comments: This method is used to generate  a list of tuples in the form ( AID , GID ). <br>
      </p>

      <li><a id="genAidFeatureDictList" href="#genAidFeatureDictList">genAidFeatureDictList(mapFL)</a></li>
      <p>
              a.  Arguments: AID-Feature map file(JSON) <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python List Object (A list of tuples)<br>
              e.  Comments: This method is used to generate a list of dictionaries in the form [{'AID': xx,'NID' : xx ,.. }]. This object will give us the capability to iterate through all annotations and their respective features.<br>
      </p>

      <li><a id="genAidFeatureDictDict" href="#genAidFeatureDictDict">genAidFeatureDictDict(mapFL)</a></li>
      <p>
              a.  Arguments: AID-Feature map file(JSON) <br>
              b.  Argument data-type: str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d.  Returns: A Python Dictionary<br>
              e.  Comments: This method is used to generate a dictionary in the form { AID : {'NID' : xxx , 'SPECIES' : xxx, .. }}. This object will give us the capability to query one/multiple features given a annotation ID.<br>
      </p>

      <li><a id="extractImageFeaturesFromMap" href="#extractImageFeaturesFromMap">extractImageFeaturesFromMap(gidAidMapFl,aidFtrMapFl,feature)</a></li>
      <p>
              a.  Arguments: GID-AID map file(JSON), AID-Feature map file(JSON), feature <br>
              b.  Argument data-type: str, str, str<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              &nbsp &nbsp ii.  The feature list should contain elements from the acceptable set of features. <br>
              d. Returns: A Python Dictionary object. <br>
              e.  Comments: This method is used to generate a dictionary in the form { GID : [list of features instances in that image]}. This object will give us the capability to check what feature instances are present in a given image. <br>
      </p>

      <li><a id="createResultDict" href="#createResultDict">createResultDict(jobRangeStart,jobRangeEnd,workerData)</a></li>
      <p>
              a.  Arguments: Start of the results file, end of the results files. <br>
              b.  Argument data-type: int, int<br>
              c.  PRE-condition: <br>
              d. Returns: A Python Dictionary object. <br>
              e.  Comments: Every album corresponds to a .result file which is extracted from the Amazon Mechanical Turk interface. This method parses the results file and generates a python object consisting of each response key with the actual response from the users. The dictionary is of the form: { photo_album_i : { Answer.GID : [ GID|'share' , 'GID'|'noShare'] }} All the results file from jobRangeStart to jobRangeEnd will be parsed and included in the output object. When the workerData parameter is set to True, turker ID's who worked on a particular album is included in the result object.<br>
      </p>

      <li><a id="imgShareCountsPerAlbum" href="#imgShareCountsPerAlbum">imgShareCountsPerAlbum(imgAlbumDict,results)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format, results is the direct output of the method <a href="#createResultDict">createResultDict()</a> <br>
              b.  Argument data-type: str, Python Dictionary object<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d. Returns: 2 Python List object. <br>
              e.  Comments: This method returns a Python list which gives us the capability to iterate through all the images, the number of times an image was shared or not shared in a particular album. This object will form the basis of all statistic computations in the project. The format of a tuple inside the list is of the form (GID, Album, Share count, Not Share count, Proportion). The other return object is the list of all (GID, albums) for which there was no valid response. (Form fields in certain albums in experiment 2 were not mandatory in the beginning, the bug was identified and corrected in a later stage.)<br>
      </p>

      <li><a id="genMSAIDataHighConfidenceTags" href="#genMSAIDataHighConfidenceTags">genMSAIDataHighConfidenceTags(tagInpDataFl,threshold)</a></li>
      <p>
              a.  Arguments: Tag input file in JSON format, confidence threshold (between 0 and 1)<br>
              b.  Argument data-type: str, float<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for tagInpDataFl and the file should exist.<br>
              d. Returns: Python Dictionary object. <br>
              e.  Comments: This method is used to generate the list of tags generated by Microsoft Image tagging API, thresholded by confindence. With each tag, there is an associated confidence which quantifies the confidence of the tag prediciting algorithm. For purpose of experiments, the threshold is defaulted to 0.5, any tags predicted with confidence greater than 0.5 is accepted and the rest is rejected.<br>
      </p>

      <li><a id="auditResMap" href="#auditResMap">auditResMap(imgAlbumDict,resultList)</a></li>
      <p>
              a.  Arguments: Image Job Map in CSV format, results is the direct output of the method <a href="#imgShareCountsPerAlbum">imgShareCountsPerAlbum()</a> <br>
              b.  Argument data-type: str, Python list object<br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Entire path is provided for imgJobMap and the file should exist.<br>
              d. Returns: 3 boolean variables. <br>
              e.  Comments: This method is an audit method that ensures there are no leaks or incorrect data in the result and feature objects. The 3 boolean variables indicate 3 different types of errors.<br>
              &nbsp &nbsp i. If error1 is returned as True it means there are images in the result objects that were not originally a part of the map file<br>
              &nbsp &nbsp ii. If error2 is returned as True it means there are images in the map file but not in results file. <br>
              &nbsp &nbsp iii. If error3 is returned as True it means there are images in the results file that are not in the map file. 
      </p>

      </ul>
      </div>


      <h3>
      <a id="PopulationEstimatorFromClf" class="anchor" href="#PopulationEstimatorFromClf" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span>PopulationEstimatorFromClf.py</a></h3>
      <div id="descContent"><p>
      Description: Contains methods to run population estimation synthetic experiements.</p></div>
      <div id="codeContent">
      <ul>
      <li><a id="trainTestClf" href="#trainTestClf">trainTestClf(train_data_fl,test_data_fl,clf,attribType,infoGainFl,methArgs)</a></li>
      <p>
              a.  Argument: Training data in CSV format, Testing data in CSV format, Classifier method name, attribute selection method name, Information gain file in CSV format, keyword arguments for classifiers.  <br>
              b.  Argument data-type: str, str, str, str, str, dict <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Files should exist <br> 
              d.  Returns: Classifier object, shared(1) not-shared(0) predictions  <br>
              e.  Return data-type: ClassifierCapsuleClass object, Python dictionary object <br>
              f.  Comments: This method is a wrapper method to build and run classifiers using the training and the testing data respecitively. There are no checks to determine if there is any overlap between training and testing data files.<br>  
      </p>

      <li><a id="biasedCoinFlipper" href="#biasedCoinFlipper">biasedCoinFlipper(p)</a></li>
      <p>
              a.  Arguments: Probability <br>
              b.  Argument data-type: float <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  p should be between 0 and 1 <br>
              d.  Returns: 0/1 <br>
              e.  Return data-type: int <br>
              f.  Comments: As the name suggests, this is a biased coin flipper. Simulates flipping a biased coin with a bias of p. Heads mean 1 and tail mean 0. <br>
      </p>
      
      <li><a id="trainTestRgrs" href="#trainTestRgrs">trainTestRgrs(train_data_fl,test_data_fl,clf,attribType,infoGainFl,methArgs)</a></li>
      <p>
              a.  Argument: Training data in CSV format, Testing data in CSV format, Classifier method name, attribute selection method name, Information gain file in CSV format, keyword arguments for classifiers.  <br>
              b.  Argument data-type: str, str, str, str, str, dict <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Files should exist <br> 
              d.  Returns: Regression object, Likelihoods of an image being shared.  <br>
              e.  Return data-type: RegressionCapsuleclass object, Python dictionary object <br>
              f.  Comments: This method is a wrapper method to build and run regressors using the training and the testing data respecitively. There are no checks to determine if there is any overlap between training and testing data files.<br>  
      </p>

      <li><a id="estimatePopulation" href="#estimatePopulation">estimatePopulation(prediction_results,inExifFl,inGidAidMapFl,inAidFtrFl)</a></li>
      <p>
              a.  Arguments: Prediction results, EXIF information of images in JSON, GID-AID map file(JSON), AID-Feature map file(JSON)<br>
              b.  Argument data-type: Python dict, str, str, str <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Files should exist.<br>
              d.  Returns: Populaion of zebras, giraffes and all animals <br>
              e.  Return data-type: Python dict object <br>
              f.  Comments: This method is used to actually estimate the population. This method utilizes methods from MarkRecapHelper to calculate the population of all animals, zebras and giraffes on the basis of the prediction results that are generated by the classifiers or regressor predictions.<br>
      </p>

      <li><a id="kSharesPerContribAfterCoinFlip" href="#kSharesPerContribAfterCoinFlip">kSharesPerContribAfterCoinFlip(prediction_results,inExifFl,inGidAidMapFl,inAidFtrFl,genk)</a></li>
      <p>
              a.  Arguments: Prediction results, EXIF information of images in JSON, GID-AID map file(JSON), AID-Feature map file(JSON), function to generate the value of k<br>
              b.  Argument data-type: Python dict, str, str, str, Python function object <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Files should exist.<br>
              d.  Returns: Populaion of zebras, giraffes and all animals when each contributor shares k images <br>
              e.  Return data-type: Python dict object <br>
              f.  Comments: This method is used to actually estimate the population when each contributor shares top k images. The images are ranked on the basis of the likelihood estimates obtained from the regression models. Since the regression outputs are a likelihood, to make a choice of whether or not each photo will be shared a coin with bias equal to likelihood of the picture being shared is flipped. <br>
      </p>

      <li><a id="kSharesPerContributor" href="#kSharesPerContributor">kSharesPerContributor(prediction_probabs,inExifFl,inGidAidMapFl,inAidFtrFl,genk)</a></li>
      <p>
              a.  Arguments: Prediction results, EXIF information of images in JSON, GID-AID map file(JSON), AID-Feature map file(JSON), function to generate the value of k<br>
              b.  Argument data-type: Python dict, str, str, str, Python function object <br>
              c.  PRE-condition: <br>
              &nbsp &nbsp i.  Files should exist.<br>
              d.  Returns: Populaion of zebras, giraffes and all animals when each contributor shares k images <br>
              e.  Return data-type: Python dict object <br>
              f.  Comments: This method is used to actually estimate the population when each contributor shares top k images. The images are ranked on the basis of the likelihood estimates obtained from the regression models. Since the regression outputs are a likelihood, to make a choice of whether or not each photo will be shared a coin with bias equal to likelihood of the picture being shared is flipped. <br>
      </p>
      
      </ul>
      </div>
      <br>

      </section>
    </div>

    
  </body>
</html>
