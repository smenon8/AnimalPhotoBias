{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Notebook name: ImageShareabilityClassifiers.ipynb\n",
    "#### Author: Sreejith Menon (smenon8@uic.edu)\n",
    "\n",
    "### General Description:\n",
    "Multiple features are extracted per image.    \n",
    "The features are majorly classified as:\n",
    "* Bilogical features like age, species, sex\n",
    "* Ecological features like yaw, view_point\n",
    "* Image EXIF/Quality data: unixtime, latitude, longitude, quality\n",
    "* Tags generated by Microsoft Image tagging API\n",
    "* Image Contributor - Sparse attribute\n",
    "* Individual animals (NID)\n",
    "\n",
    "Based on these features mutliple classification algorithms are implemented and the metrics are evaluated. The aim of the classification algorithms is to predict given features, will a certain image be shared/not shared on a social media platform.    \n",
    "The ClassifierHelperAPI has *off-the-shelf* implementations from `sk-learn` library and uses a Classifier Object to store the metrics of each classifier.    \n",
    "The performance metrics evaluated are:\n",
    "* Accuracy - Number of correct predictions in the test data\n",
    "* Precision \n",
    "* Recall\n",
    "* F1 score\n",
    "* Absolute Error\n",
    "* AUC\n",
    "* Squared Error - Not displayed currently\n",
    "* Zero One Hinge Loss - Not displayed currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ClassiferHelperAPI as CH\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "importlib.reload(CH)\n",
    "from ast import literal_eval\n",
    "import plotly.plotly as py\n",
    "import htmltag as HT\n",
    "import cufflinks as cf # this is necessary to link pandas to plotly\n",
    "cf.go_online()\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from collections import Counter\n",
    "import csv\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building data for the Classifier\n",
    "* Discretizing non-binary data using the bag-of-words model\n",
    "* Building and running the classifer for all train-test splits starting from 10% upto 90%\n",
    "* Computing the performance metrics for each of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allAttribs = CH.genAllAttribs(\"../FinalResults/ImgShrRnkListWithTags.csv\",\"sparse\",\"../data/infoGains.csv\")\n",
    "data= CH.getMasterData(\"../FinalResults/ImgShrRnkListWithTags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Block of code for building and running the classifier\n",
    "# Will generate custom warnings, setting scores to 0, if there are no valid predictions\n",
    "methods = ['logistic','svm','dtree','random_forests','ada_boost']\n",
    "methods = ['ada_boost']\n",
    "\n",
    "classifiers = []\n",
    "for method in methods:\n",
    "    for i in np.arange(0.4,0.5,0.1):\n",
    "        clfObj = CH.buildBinClassifier(data,allAttribs,1-i,80,method)\n",
    "        clfObj.runClf()\n",
    "        classifiers.append(clfObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing all the scores into a pandas data-frame and then into a CSV file\n",
    "printableClfs = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    printableClfs.append(dict(literal_eval(clf.__str__())))\n",
    "    \n",
    "df = pd.DataFrame(printableClfs)\n",
    "df = df[['methodName','splitPercent','accScore','precision','recall','f1Score','auc','sqerr']]\n",
    "df.columns = ['Classifier','Train-Test Split','Accuracy','Precision','Recall','F1 score','AUC','Squared Error']\n",
    "# df.to_csv(\"../ClassifierResults/extrmClfMetrics_abv_mean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Will take up valuable Plot.ly plots per day. Limited to 50 plots per day.\n",
    "# changes to file name important\n",
    "iFrameBlock = []\n",
    "for i in np.arange(0.4,0.5,0.1):\n",
    "    df1 = df[(df['Train-Test Split']==1-i)]\n",
    "    df1.index = df1['Classifier']\n",
    "    df1 = df1[['Accuracy','Precision','Recall','F1 score','AUC','Squared Error']].transpose()\n",
    "    df1.iplot(kind='bar',filename=str('Train-Test_Split_Ratio_abv_mean %f' %i),title=str('Train-Test Split Ratio: %f' %i))\n",
    "    # iFrameBlock.append(fig.embed_code)\n",
    "\n",
    "# with open(\"../ClassifierResults/performanceComparisonsparse.html\",\"w\") as perf:\n",
    "#     perf.write(HT.h1(\"Performance Comparisons of Classifiers with non_sparse Attributes.\"))\n",
    "#     for row in iFrameBlock:\n",
    "#         perf.write(HT.HTML(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating weights of features in the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfWeights = []\n",
    "for clf in classifiers:\n",
    "    clfAttribs = list(clf.test_x.columns)\n",
    "    if clf.methodName == 'logistic':\n",
    "        clfAttribWgts = list(clf.clfObj.coef_[0])\n",
    "    elif clf.methodName == 'dtree' or clf.methodName == 'random_forests':\n",
    "        clfAttribWgts = list(clf.clfObj.feature_importances_)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    attribWgt = {clfAttribs[i] : clfAttribWgts[i] for i in range(len(clfAttribs))}\n",
    "    attribWgt['Method'] = clf.methodName\n",
    "    attribWgt['Split_Percent'] = clf.splitPercent\n",
    "        \n",
    "    clfWeights.append(attribWgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfDf = pd.DataFrame(clfWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indDF = clfDf[(clfDf['Method']=='logistic')]\n",
    "indDF.index = indDF['Split_Percent']\n",
    "indDF.drop('Method',1,inplace=True)  \n",
    "indDF.transpose().to_csv(\"../ClassifierResults/LogisiticWeights.csv\")\n",
    "\n",
    "indDF = clfDf[(clfDf['Method']=='dtree')]\n",
    "indDF.index = indDF['Split_Percent']\n",
    "indDF.drop('Method',1,inplace=True)  \n",
    "indDF.transpose().to_csv(\"../ClassifierResults/DecisionTreeWeights.csv\")\n",
    "\n",
    "indDF = clfDf[(clfDf['Method']=='random_forests')]\n",
    "indDF.index = indDF['Split_Percent']\n",
    "indDF.drop('Method',1,inplace=True)  \n",
    "indDF.transpose().to_csv(\"../ClassifierResults/RandomForestsWeights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logisticDf = clfDf[(clfDf['Method']=='logistic')]\n",
    "del logisticDf['Method']\n",
    "del logisticDf['Split_Percent']\n",
    "dtreeDf = clfDf[(clfDf['Method']=='dtree')]\n",
    "del dtreeDf['Method']\n",
    "del dtreeDf['Split_Percent']\n",
    "randomForestDf = clfDf[(clfDf['Method']=='random_forests')]\n",
    "del randomForestDf['Method']\n",
    "del randomForestDf['Split_Percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logisticDf = logisticDf.transpose()\n",
    "logisticDf.reset_index(inplace=True)\n",
    "logisticDf.columns = ['Feature','10%','20%','30%','40%','50%','60%','70%','80%','90%']\n",
    "dfs_logistic = []\n",
    "for i in range(10,100,10):\n",
    "    prcnt = str(i)+'%'\n",
    "    logisticDf.sort_values(by=prcnt,inplace=True,ascending=False)\n",
    "    df = logisticDf[['Feature',prcnt]].head(15)\n",
    "    df.index = np.arange(1,16,1)\n",
    "    \n",
    "    dfs_logistic.append(df)\n",
    "    \n",
    "concatdf_logisitc = pd.concat([dfs_logistic[0],dfs_logistic[1],dfs_logistic[2],dfs_logistic[3],dfs_logistic[4],dfs_logistic[5],dfs_logistic[6],dfs_logistic[7],dfs_logistic[8]],axis=1)\n",
    "concatdf_logisitc.to_csv(\"../ClassifierResults/Top15_Weights_Logisitic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtreeDf = dtreeDf.transpose()\n",
    "dtreeDf.reset_index(inplace=True)\n",
    "dtreeDf.columns = ['Feature','10%','20%','30%','40%','50%','60%','70%','80%','90%']\n",
    "dfs_tree = []\n",
    "for i in range(10,100,10):\n",
    "    prcnt = str(i)+'%'\n",
    "    dtreeDf.sort_values(by=prcnt,inplace=True,ascending=False)\n",
    "    df = dtreeDf[['Feature',prcnt]].head(15)\n",
    "    df.index = np.arange(1,16,1)\n",
    "    \n",
    "    dfs_tree.append(df)\n",
    "    \n",
    "concatdf_dtree = pd.concat([dfs_tree[0],dfs_tree[1],dfs_tree[2],dfs_tree[3],dfs_tree[4],dfs_tree[5],dfs_tree[6],dfs_tree[7],dfs_tree[8]],axis=1)\n",
    "concatdf_dtree.to_csv(\"../ClassifierResults/Top15_Weights_Dtree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomForestDf = randomForestDf.transpose()\n",
    "randomForestDf.reset_index(inplace=True)\n",
    "randomForestDf.columns = ['Feature','10%','20%','30%','40%','50%','60%','70%','80%','90%']\n",
    "dfs_rndf = []\n",
    "for i in range(10,100,10):\n",
    "    prcnt = str(i)+'%'\n",
    "    randomForestDf.sort_values(by=prcnt,inplace=True,ascending=False)\n",
    "    df = randomForestDf[['Feature',prcnt]].head(15)\n",
    "    df.index = np.arange(1,16,1)\n",
    "    \n",
    "    dfs_rndf.append(df)\n",
    "    \n",
    "concatdf_rndf = pd.concat([dfs_rndf[0],dfs_rndf[1],dfs_rndf[2],dfs_rndf[3],dfs_rndf[4],dfs_rndf[5],dfs_rndf[6],dfs_rndf[7],dfs_rndf[8]],axis=1)\n",
    "concatdf_rndf.to_csv(\"../ClassifierResults/Top15_Weights_Rndf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attribs = [list(dfs_logistic[i]['Feature']) for i in range(0,9)]\n",
    "attribs = [attrib for listAttrib in attribs for attrib in listAttrib]\n",
    "pd.DataFrame(Counter(attribs),index=['Frequency']).transpose().sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attribs = [list(dfs_tree[i]['Feature']) for i in range(0,9)]\n",
    "attribs = [attrib for listAttrib in attribs for attrib in listAttrib]\n",
    "pd.DataFrame(Counter(attribs),index=['Frequency']).transpose().sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attribs = [list(dfs_rndf[i]['Feature']) for i in range(0,9)]\n",
    "attribs = [attrib for listAttrib in attribs for attrib in listAttrib]\n",
    "pd.DataFrame(Counter(attribs),index=['Frequency']).transpose().sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attribs = [list(dfs_logistic[i]['Feature']) for i in range(0,9)]\n",
    "attribs += [list(dfs_tree[i]['Feature']) for i in range(0,9)]\n",
    "attribs += [list(dfs_rndf[i]['Feature']) for i in range(0,9)]\n",
    "attribs = [attrib for listAttrib in attribs for attrib in listAttrib]\n",
    "pd.DataFrame(Counter(attribs),index=['Frequency']).transpose().sort_values(by=['Frequency'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logisticDf.sort_values(by='10%',inplace=True,ascending=False)\n",
    "fig = {\n",
    "    'data' : [\n",
    "        {'x' : logisticDf.Feature.head(15),'y' : logisticDf['10%'].head(15), 'mode' : 'markers', 'name' : '10%'}\n",
    "    ]\n",
    "}\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj1.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers[0].preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data= CH.getMasterData(\"../FinalResults/ImgShrRnkListWithTags.csv\")  \n",
    "methods = ['dummy','bayesian','logistic','svm','dtree','random_forests','ada_boost']\n",
    "kwargsDict = {'dummy' : {'strategy' : 'most_frequent'},\n",
    "            'bayesian' : {'fit_prior' : True},\n",
    "            'logistic' : {'penalty' : 'l2'},\n",
    "            'svm' : {'kernel' : 'rbf','probability' : True},\n",
    "            'dtree' : {'criterion' : 'entropy'},\n",
    "            'random_forests' : {'n_estimators' : 10 },\n",
    "            'ada_boost' : {'n_estimators' : 50 }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAttribs = CH.genAllAttribs(\"../FinalResults/ImgShrRnkListWithTags.csv\",'non_sparse',\"../data/infoGainsExpt2.csv\")\n",
    "clfObj = CH.buildBinClassifier(data,allAttribs,1-0.5,80,'dtree',kwargsDict['dtree'])\n",
    "clfObj.runClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.66666666666666663, 0.7068965517241379, 'dtree')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfObj.precision,clfObj.recall,clfObj.methodName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"f553d496-b40b-4074-a711-621c12dc1627\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f553d496-b40b-4074-a711-621c12dc1627\", [{\"type\": \"scatter\", \"text\": \"\", \"y\": [0.0, 0.7068965517241379, 0.7155172413793104, 1.0], \"mode\": \"lines\", \"line\": {\"width\": 1.3, \"dash\": \"solid\", \"color\": \"rgba(255, 153, 51, 1.0)\"}, \"name\": \"tpr\", \"x\": [0.0, 0.43157894736842106, 0.4421052631578947, 1.0]}], {\"plot_bgcolor\": \"#F5F6F9\", \"yaxis1\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": \"\", \"zerolinecolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}}, \"xaxis1\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": \"\", \"zerolinecolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}}, \"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"titlefont\": {\"color\": \"#4D5663\"}, \"paper_bgcolor\": \"#F5F6F9\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr,tpr,_ = clfObj.roccurve\n",
    "rocCurve = {}\n",
    "for i in range(len(fpr)):\n",
    "    rocCurve[fpr[i]] = tpr[i]\n",
    "    \n",
    "pd.DataFrame(rocCurve,index=['tpr']).transpose().iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_fl = \"../FinalResults/ImgShrRnkListWithTags.csv\"\n",
    "attribType = 'non_zero'\n",
    "infoGainFl = \"../data/infoGainsExpt2.csv\"\n",
    "allAttribs = CH.genAllAttribs(train_data_fl,attribType,infoGainFl)\n",
    "\n",
    "train_data= CH.getMasterData(train_data_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CH.buildBinClassifier(train_data,allAttribs,0.0,80,clf,clfArgs.get(clf,None))\n",
    "# readyDict = CH.createDataFlDict(train_data,allAttribs,80,dataMode='regression',ftrs=['SPECIES','SEX','AGE','QUALITY','VIEW_POINT'])\n",
    "readyDict = CH.createDataFlDict(train_data,allAttribs,80,dataMode='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(readyDict).transpose()\n",
    "dfCol = df.columns\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['GID'] + list(dfCol)\n",
    "df['GID'] = df['GID'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResults = pd.DataFrame.from_csv(train_data_fl)['Proportion'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressionData = pd.merge(df,dfResults,on='GID')\n",
    "regressionData.drop(['GID'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Female</th>\n",
       "      <th>IBEIS_PZ_0001</th>\n",
       "      <th>IBEIS_PZ_0003</th>\n",
       "      <th>IBEIS_PZ_0005</th>\n",
       "      <th>IBEIS_PZ_0007</th>\n",
       "      <th>IBEIS_PZ_0010</th>\n",
       "      <th>IBEIS_PZ_0011</th>\n",
       "      <th>IBEIS_PZ_0012</th>\n",
       "      <th>IBEIS_PZ_0013</th>\n",
       "      <th>IBEIS_PZ_0014</th>\n",
       "      <th>...</th>\n",
       "      <th>tall</th>\n",
       "      <th>tree</th>\n",
       "      <th>unknown</th>\n",
       "      <th>walking</th>\n",
       "      <th>water</th>\n",
       "      <th>way</th>\n",
       "      <th>wild</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zebra_plains</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Female  IBEIS_PZ_0001  IBEIS_PZ_0003  IBEIS_PZ_0005  IBEIS_PZ_0007  \\\n",
       "0     1.0            NaN            NaN            NaN            NaN   \n",
       "1     0.0            NaN            NaN            NaN            NaN   \n",
       "2     0.0            NaN            NaN            NaN            NaN   \n",
       "3     0.0            NaN            NaN            NaN            NaN   \n",
       "4     0.0            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   IBEIS_PZ_0010  IBEIS_PZ_0011  IBEIS_PZ_0012  IBEIS_PZ_0013  IBEIS_PZ_0014  \\\n",
       "0            NaN            0.0            NaN            0.0            NaN   \n",
       "1            NaN            0.0            NaN            0.0            NaN   \n",
       "2            NaN            0.0            NaN            0.0            NaN   \n",
       "3            NaN            0.0            NaN            0.0            NaN   \n",
       "4            NaN            0.0            NaN            0.0            NaN   \n",
       "\n",
       "      ...      tall  tree  unknown  walking  water  way  wild  zebra  \\\n",
       "0     ...       1.0   0.0      0.0      1.0    0.0  0.0   1.0    0.0   \n",
       "1     ...       1.0   0.0      0.0      0.0    0.0  0.0   0.0    1.0   \n",
       "2     ...       0.0   1.0      0.0      0.0    0.0  0.0   0.0    0.0   \n",
       "3     ...       1.0   1.0      0.0      0.0    0.0  0.0   0.0    0.0   \n",
       "4     ...       0.0   1.0      0.0      0.0    0.0  0.0   0.0    1.0   \n",
       "\n",
       "   zebra_plains  Proportion  \n",
       "0           0.0        20.0  \n",
       "1           1.0        80.0  \n",
       "2           0.0        50.0  \n",
       "3           0.0        30.0  \n",
       "4           1.0        10.0  \n",
       "\n",
       "[5 rows x 833 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgrObj = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Female', 'Male', 'UNKNOWN NAME', 'UNKNOWN SEX', 'adult', 'animal',\n",
       "       'antelope', 'arthropod', 'baby', 'back', 'backleft', 'backright',\n",
       "       'big cat', 'brown', 'brush', 'bushes', 'cactus', 'conifer', 'crossing',\n",
       "       'deer', 'desert', 'dirt', 'drink', 'drinking', 'dry', 'eating',\n",
       "       'elephant', 'excellent', 'field', 'forest', 'front', 'frontleft',\n",
       "       'frontright', 'giraffe', 'giraffe_masai', 'good', 'grass', 'grassy',\n",
       "       'grazing', 'green', 'ground', 'group', 'hay', 'herd', 'hill', 'hyena',\n",
       "       'infant', 'junk', 'juveniles - one year old', 'juveniles- two year old',\n",
       "       'lake', 'laying', 'leaf', 'left', 'llama', 'lone', 'looking', 'lush',\n",
       "       'mammal', 'mother', 'mountain', 'ok', 'open', 'outdoor', 'path',\n",
       "       'plain', 'plant', 'pond', 'poor', 'right', 'river', 'road', 'running',\n",
       "       'sheep', 'sky', 'standing', 'tall', 'tree', 'unknown', 'walking',\n",
       "       'water', 'way', 'wild', 'zebra', 'zebra_plains', 'Proportion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressionData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = regressionData[['Female', 'Male', 'UNKNOWN NAME', 'UNKNOWN SEX', 'adult', 'animal',\n",
    "       'antelope', 'arthropod', 'baby', 'back', 'backleft', 'backright',\n",
    "       'big cat', 'brown', 'brush', 'bushes', 'cactus', 'conifer', 'crossing',\n",
    "       'deer', 'desert', 'dirt', 'drink', 'drinking', 'dry', 'eating',\n",
    "       'elephant', 'excellent', 'field', 'forest', 'front', 'frontleft',\n",
    "       'frontright', 'giraffe', 'giraffe_masai', 'good', 'grass', 'grassy',\n",
    "       'grazing', 'green', 'ground', 'group', 'hay', 'herd', 'hill', 'hyena',\n",
    "       'infant', 'junk', 'juveniles - one year old', 'juveniles- two year old',\n",
    "       'lake', 'laying', 'leaf', 'left', 'llama', 'lone', 'looking', 'lush',\n",
    "       'mammal', 'mother', 'mountain', 'ok', 'open', 'outdoor', 'path',\n",
    "       'plain', 'plant', 'pond', 'poor', 'right', 'river', 'road', 'running',\n",
    "       'sheep', 'sky', 'standing', 'tall', 'tree', 'unknown', 'walking',\n",
    "       'water', 'way', 'wild', 'zebra', 'zebra_plains']]\n",
    "y = regressionData['Proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.4,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgrObj.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = rgrObj.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy = list(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = [testy[i]-preds[i] for i in range(len(preds)) if abs(testy[i]-preds[i]) <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2549046579889751"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(errors)/len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outliers = [testy[i]-preds[i] for i in range(len(preds)) if abs(testy[i]-preds[i]) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-144222989624324.97,\n",
       " -1214150026129.988,\n",
       " 4091148871.587543,\n",
       " 253665574945685.31,\n",
       " 880660374527255.38,\n",
       " -501903394479.68677,\n",
       " 6400542402051.9121,\n",
       " -103563922197765.53]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
